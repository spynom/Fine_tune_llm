{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:25.773159Z",
     "start_time": "2024-11-05T04:24:25.769777Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "beca0ef364f4d771",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quantization",
   "id": "feb89d44581e5889"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Quantization refers to the process of mapping a large set to smaller set of values (the higher precision to the lower precision)**\n",
   "id": "9ed6e0a4f7061c39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "![](images/img.png)"
   ],
   "id": "d7f81092bbcb16fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Original Tensor**\n",
    "|    |     |     |\n",
    "|----|-----|-----|\n",
    "| 191.6 | -13.5 | 728.6 |\n",
    "| 92.14 | 295.5 | -184  |\n",
    "| 0     | 684.6 | 245.5 |\n",
    "\n",
    "**Quantized Tensor**\n",
    "|   |   |   |\n",
    "|--|--|--|\n",
    "|-23|-81|127|\n",
    "|-51|6|-128|\n",
    "|-77|114|-8|"
   ],
   "id": "b6788fa184b68b9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Advantage of Quantization",
   "id": "951fc9290a0e5af7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Smaller model\n",
    "- speed gains\n",
    "    - memory bandwidth\n",
    "    - Faster operation\n",
    "        - GEMM: General  Matrix Multiplication\n",
    "        - GEMV: General Matrix Vector Multiplication"
   ],
   "id": "34eec48e9c8f12c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Challenges Of Quantization",
   "id": "8fa13cc7318307ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Quantization Error\n",
    "- Retraining (Quantization Aware Training)\n",
    "- Limited Hardware Support\n",
    "- Calibration Dataset Needed\n",
    "- Packing / Unpacking"
   ],
   "id": "b4f300ea88e494fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear Quantization",
   "id": "f9678d5a63fba278"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](images/img_1.png)",
   "id": "25ba93db6bf4a1dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Idea:** Linear Mapping <br>\n",
    " $$ r = s(q-z)$$\n",
    " **WHERE,**<br>\n",
    " $r$: Original Value<br>\n",
    " $s$: Scale<br>\n",
    " $q$: Quantized value<br>\n",
    " $z$: zero-point \n",
    " \n",
    "**EXAMPLE**<br>\n",
    "Assume $s = 2$ , $z = 0$, then <br>\n",
    "$ r = 2(q-0) = 2q$ <br>\n",
    "for $q = 10$, we have $r = 2*10 = 20$ "
   ],
   "id": "ff22fc88c1dc5bdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:25.792455Z",
     "start_time": "2024-11-05T04:24:25.789476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dequantised_tensor(tensor,scale,zero_point):\n",
    "    return scale * (tensor.float()-zero_point)\n",
    "    "
   ],
   "id": "53239ff660714405",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### How do we get the quantized tensor q ?\n",
   "id": "75930e8b6481e9a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "as we know $ r = s(q-z)$<br>\n",
    "then, $ r/s = q-z $<br>\n",
    "then, $ r/s-z =q$ can also be written as $ q = r/s-z$<br>\n",
    "then, $ round(r/s -z) $ , to eliminate floating-point overflow<br>\n",
    "at end, $ q = int( round (r/s - z))$"
   ],
   "id": "c5ed1f6cabeb783b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### with random value for `scaler` and `Zero-point`",
   "id": "adee8561b6c1846c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:25.873808Z",
     "start_time": "2024-11-05T04:24:25.868805Z"
    }
   },
   "source": [
    "def linear_q_with_scale_and_zero_point(\n",
    "    tensor, scale, zero_point, dtype = torch.int8):\n",
    "\n",
    "    scaled_and_shifted_tensor = tensor / scale + zero_point\n",
    "\n",
    "    rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "\n",
    "    q_min = torch.iinfo(dtype).min\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "\n",
    "    q_tensor = rounded_tensor.clamp(q_min,q_max).to(dtype)\n",
    "    \n",
    "    return q_tensor"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:25.928640Z",
     "start_time": "2024-11-05T04:24:25.925437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### a dummy tensor to test the implementation\n",
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ],
   "id": "c75479542af6580b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:25.976390Z",
     "start_time": "2024-11-05T04:24:25.973652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scale = 2.03\n",
    "zero_point = 0"
   ],
   "id": "e51a6f9875c443b2",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.029387Z",
     "start_time": "2024-11-05T04:24:26.025724Z"
    }
   },
   "cell_type": "code",
   "source": "quantized_tensor = linear_q_with_scale_and_zero_point(test_tensor, scale, zero_point, dtype = torch.int8)",
   "id": "6b323fdfd281abda",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.094246Z",
     "start_time": "2024-11-05T04:24:26.088327Z"
    }
   },
   "cell_type": "code",
   "source": "quantized_tensor",
   "id": "e94bf3e9236da538",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 94,  -7, 127],\n",
       "        [ 45, 127, -91],\n",
       "        [  0, 127, 121]], dtype=torch.int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.297229Z",
     "start_time": "2024-11-05T04:24:26.294388Z"
    }
   },
   "cell_type": "code",
   "source": "dequantized_tensor = get_dequantised_tensor(quantized_tensor,scale,zero_point)",
   "id": "1e13c3b9a19d66b3",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.353172Z",
     "start_time": "2024-11-05T04:24:26.347074Z"
    }
   },
   "cell_type": "code",
   "source": "dequantized_tensor",
   "id": "e3c66727bd24b62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 190.8200,  -14.2100,  257.8100],\n",
       "        [  91.3500,  257.8100, -184.7300],\n",
       "        [   0.0000,  257.8100,  245.6300]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.475880Z",
     "start_time": "2024-11-05T04:24:26.469818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quantized error\n",
    "torch.square(test_tensor-dequantized_tensor).mean()"
   ],
   "id": "d7afc565e399896",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45023.9648)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### without random",
   "id": "cff513ddf5f5bfa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.564465Z",
     "start_time": "2024-11-05T04:24:26.559523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_q_scale_and_zero_point(tensor, dtype=torch.int8):\n",
    "    \n",
    "    q_min, q_max = torch.iinfo(dtype).min, torch.iinfo(dtype).max\n",
    "    r_min, r_max = tensor.min().item(), tensor.max().item()\n",
    "\n",
    "    scale = (r_max - r_min) / (q_max - q_min)\n",
    "\n",
    "    zero_point = q_min - (r_min / scale)\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < q_min:\n",
    "        zero_point = q_min\n",
    "    elif zero_point > q_max:\n",
    "        zero_point = q_max\n",
    "    else:\n",
    "        # round and cast to int\n",
    "        zero_point = int(round(zero_point))\n",
    "    \n",
    "    return scale, zero_point"
   ],
   "id": "a2daf396c5558b60",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.647070Z",
     "start_time": "2024-11-05T04:24:26.643537Z"
    }
   },
   "cell_type": "code",
   "source": "scale, zero_point = get_q_scale_and_zero_point(test_tensor)",
   "id": "6415dd0b6caa4ada",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.709640Z",
     "start_time": "2024-11-05T04:24:26.703665Z"
    }
   },
   "cell_type": "code",
   "source": "scale",
   "id": "6185739a3fec9411",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.578823433670343"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.767351Z",
     "start_time": "2024-11-05T04:24:26.762466Z"
    }
   },
   "cell_type": "code",
   "source": "zero_point",
   "id": "a9b55e822a486649",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-77"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.817097Z",
     "start_time": "2024-11-05T04:24:26.814599Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e9e16f862dd6b98d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.864549Z",
     "start_time": "2024-11-05T04:24:26.861362Z"
    }
   },
   "cell_type": "code",
   "source": "quantized_tensor = linear_q_with_scale_and_zero_point(test_tensor, scale, zero_point, dtype = torch.int8)",
   "id": "136a2c2c2102cd01",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:26.921032Z",
     "start_time": "2024-11-05T04:24:26.915296Z"
    }
   },
   "cell_type": "code",
   "source": "quantized_tensor",
   "id": "fda52c4fdd07f2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -23,  -81,  127],\n",
       "        [ -51,    6, -128],\n",
       "        [ -77,  114,   -8]], dtype=torch.int8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.001296Z",
     "start_time": "2024-11-05T04:24:26.997675Z"
    }
   },
   "cell_type": "code",
   "source": "dequantised_tensor = get_dequantised_tensor(quantized_tensor,scale,zero_point)",
   "id": "cc98053cae65859a",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.057028Z",
     "start_time": "2024-11-05T04:24:27.050861Z"
    }
   },
   "cell_type": "code",
   "source": "dequantized_tensor",
   "id": "759b19695848a68f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 190.8200,  -14.2100,  257.8100],\n",
       "        [  91.3500,  257.8100, -184.7300],\n",
       "        [   0.0000,  257.8100,  245.6300]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.164408Z",
     "start_time": "2024-11-05T04:24:27.159638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quantized error\n",
    "torch.square(test_tensor-dequantised_tensor).mean()"
   ],
   "id": "d68f1b5b32c97c10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5730)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Let's write all functions in  class format",
   "id": "aa401a9e728b7a4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.241901Z",
     "start_time": "2024-11-05T04:24:27.232660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Quantizer:\n",
    "        \n",
    "    def quantize(self, tensor,dtype=torch.int8):\n",
    "        self.r_tensor = tensor\n",
    "        self.scale, self.zero_point = self.get_q_scale_and_zero_point(tensor)\n",
    "        scaled_and_shifted_tensor = tensor / self.scale + self.zero_point\n",
    "    \n",
    "        rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "    \n",
    "        q_min = torch.iinfo(dtype).min\n",
    "        q_max = torch.iinfo(dtype).max\n",
    "    \n",
    "        self.q_tensor = rounded_tensor.clamp(q_min,q_max).to(dtype)\n",
    "        \n",
    "        return self.q_tensor\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_q_scale_and_zero_point(tensor, dtype=torch.int8):\n",
    "    \n",
    "        q_min, q_max = torch.iinfo(dtype).min, torch.iinfo(dtype).max\n",
    "        r_min, r_max = tensor.min().item(), tensor.max().item()\n",
    "    \n",
    "        scale = (r_max - r_min) / (q_max - q_min)\n",
    "    \n",
    "        zero_point = q_min - (r_min / scale)\n",
    "    \n",
    "        # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "        if zero_point < q_min:\n",
    "            zero_point = q_min\n",
    "        elif zero_point > q_max:\n",
    "            zero_point = q_max\n",
    "        else:\n",
    "            # round and cast to int\n",
    "            zero_point = int(round(zero_point))\n",
    "        \n",
    "        return scale, zero_point\n",
    "    \n",
    "    def dequantized(self):\n",
    "        \n",
    "        self.dq_tensor = self.scale * (self.q_tensor.float()-self.zero_point)\n",
    "        return self.dq_tensor\n",
    "    \n",
    "    def quantize_error(self):\n",
    "        return torch.square(self.r_tensor-self.dequantized()).mean().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ],
   "id": "34762879a50de319",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.328884Z",
     "start_time": "2024-11-05T04:24:27.324199Z"
    }
   },
   "cell_type": "code",
   "source": "test_tensor",
   "id": "390feab354ed6a01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 191.6000,  -13.5000,  728.6000],\n",
       "        [  92.1400,  295.5000, -184.0000],\n",
       "        [   0.0000,  684.6000,  245.5000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.423785Z",
     "start_time": "2024-11-05T04:24:27.417228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantizer = Quantizer()\n",
    "quantizer.quantize(test_tensor)"
   ],
   "id": "6f4a7e0eb4e953a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -23,  -81,  127],\n",
       "        [ -51,    6, -128],\n",
       "        [ -77,  114,   -8]], dtype=torch.int8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.523773Z",
     "start_time": "2024-11-05T04:24:27.516631Z"
    }
   },
   "cell_type": "code",
   "source": "quantizer.dequantized()",
   "id": "2ab38e31d79a6c17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 193.2565,  -14.3153,  730.0800],\n",
       "        [  93.0494,  297.0423, -182.5200],\n",
       "        [   0.0000,  683.5552,  246.9388]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:24:27.652393Z",
     "start_time": "2024-11-05T04:24:27.646364Z"
    }
   },
   "cell_type": "code",
   "source": "quantizer.quantize_error()",
   "id": "4bde4ee7c58ed48a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5729731321334839"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Quantization Mode",
   "id": "65f53aacb5e05bc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There are **two** modes in linear quantization:\n",
    "- **Asymmetric:** We map $[r_{min},r_{max}]$ to $[q_{min},q_{max}]$. This what we implemented in previous example and code.\n",
    "- **Symmetric:** We map $[-r_{max},r_{max}]$ to $[-q_{max},q_{max}]$. Where we can set $r_{max} = max(|r\\_tensor|)$\n",
    "    - We don't need to use the zero point (z=0)\n",
    "    - This happens beacuse the floating -point range and the quantized range are symmetric with respect to zero.\n",
    "    - Hence, we can simplify the equations to:\n",
    "    $$q = int(round(r/s))$$\n",
    "    $$s = r_{max}/q_{max}$$\n",
    "    $$z = 0$$"
   ],
   "id": "f8a3c28a3cbe15e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](images/img_2.png)",
   "id": "b75ebefb6a52a82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Trade-off:**\n",
    "    - Utilization of quantized range: \n",
    "        - When using asymmetric quantization, the quantized range is fully utilized.\n",
    "        - When symmetric mode, if the float range is biased towards one side, this will result in a quantized range where a part of the range is dedicated to values that we'll never see. (e.g RELU where the output is positive). \n",
    "    - Simplicity: Symmetric mode is much simpler compared to asymmetric mode. \n",
    "    - Memory: We don't store the zero-point for symmetric quantization"
   ],
   "id": "bee60243cd4c6f21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:40:15.763521Z",
     "start_time": "2024-11-05T11:40:15.760499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_q_scale_symmetric(tensor, dtype=torch.int8):\n",
    "    r_max = tensor.abs().max().item()\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "\n",
    "    # return the scale\n",
    "    return r_max/q_max"
   ],
   "id": "9784fb983738fe6f",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### let's update the class function",
   "id": "801423c5e960c563"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:08:44.055552Z",
     "start_time": "2024-11-05T11:08:44.048141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Quantizer:\n",
    "        \n",
    "    def quantize(self, tensor,dtype=torch.int8,mode = \"symmetric\"):\n",
    "        self.r_tensor = tensor\n",
    "        if mode == \"symmetric\":\n",
    "            self.scale, self.zero_point = self.get_q_scale_symmetric(tensor), 0\n",
    "        else:\n",
    "            self.scale, self.zero_point = self.get_q_scale_and_zero_point(tensor)\n",
    "        scaled_and_shifted_tensor = tensor / self.scale + self.zero_point\n",
    "    \n",
    "        rounded_tensor = torch.round(scaled_and_shifted_tensor)\n",
    "    \n",
    "        q_min = torch.iinfo(dtype).min\n",
    "        q_max = torch.iinfo(dtype).max\n",
    "    \n",
    "        self.q_tensor = rounded_tensor.clamp(q_min,q_max).to(dtype)\n",
    "        \n",
    "        return self.q_tensor\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_q_scale_and_zero_point(tensor, dtype=torch.int8):\n",
    "    \n",
    "        q_min, q_max = torch.iinfo(dtype).min, torch.iinfo(dtype).max\n",
    "        r_min, r_max = tensor.min().item(), tensor.max().item()\n",
    "    \n",
    "        scale = (r_max - r_min) / (q_max - q_min)\n",
    "    \n",
    "        zero_point = q_min - (r_min / scale)\n",
    "    \n",
    "        # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "        if zero_point < q_min:\n",
    "            zero_point = q_min\n",
    "        elif zero_point > q_max:\n",
    "            zero_point = q_max\n",
    "        else:\n",
    "            # round and cast to int\n",
    "            zero_point = int(round(zero_point))\n",
    "        \n",
    "        return scale, zero_point\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_q_scale_symmetric(tensor, dtype=torch.int8):\n",
    "        r_max = tensor.abs().max().item()\n",
    "        q_max = torch.iinfo(dtype).max\n",
    "    \n",
    "        # return the scale\n",
    "        return r_max/q_max\n",
    "    \n",
    "    def dequantized(self):\n",
    "        \n",
    "        self.dq_tensor = self.scale * (self.q_tensor.float()-self.zero_point)\n",
    "        return self.dq_tensor\n",
    "    \n",
    "    def quantize_error(self):\n",
    "        return torch.square(self.r_tensor-self.dequantized()).mean().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ],
   "id": "46b0320cf3652eb6",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:08:32.517333Z",
     "start_time": "2024-11-05T11:08:32.399946Z"
    }
   },
   "cell_type": "code",
   "source": "test_tensor",
   "id": "ce3e57cf11282e05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 191.6000,  -13.5000,  728.6000],\n",
       "        [  92.1400,  295.5000, -184.0000],\n",
       "        [   0.0000,  684.6000,  245.5000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:08:48.158173Z",
     "start_time": "2024-11-05T11:08:48.149955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quantizer = Quantizer()\n",
    "quantizer.quantize(test_tensor)"
   ],
   "id": "599ab81b1df09005",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 33,  -2, 127],\n",
       "        [ 16,  52, -32],\n",
       "        [  0, 119,  43]], dtype=torch.int8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:08:50.975606Z",
     "start_time": "2024-11-05T11:08:50.970470Z"
    }
   },
   "cell_type": "code",
   "source": "quantizer.dequantized()",
   "id": "8115a8613cdf647b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 189.3213,  -11.4740,  728.6000],\n",
       "        [  91.7921,  298.3244, -183.5842],\n",
       "        [   0.0000,  682.7039,  246.6913]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:08:53.481215Z",
     "start_time": "2024-11-05T11:08:53.475059Z"
    }
   },
   "cell_type": "code",
   "source": "quantizer.quantize_error()",
   "id": "6fd0781c46f880b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5091912746429443"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Different Granularities for Quantization\n",
    "- For simplicity, we'll perform these using Symmetric mode.\n",
    "- In the context of quantization, **\"granularity\"** refers to the level of detail or the smallest unit of measure in which a signal or data is represented or approximated after being quantized. It typically describes the precision or resolution of the quantization process.\n",
    "\n"
   ],
   "id": "1876fa29ed572cfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](images/img_3.png)",
   "id": "b4b171d899b34864"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Per tensor\n",
    " - till now, we have been doing per tensor quantization."
   ],
   "id": "df562d93d85f893f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Per channel",
   "id": "463a91fe3f9a0f87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:36:09.563551Z",
     "start_time": "2024-11-05T11:36:09.559542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_q_symmetric_per_channel(r_tensor, dim, dtype=torch.int8): # dim =0 represent axis = 0 and dim =1 axis=1\n",
    "    \n",
    "    output_dim = r_tensor.shape[dim]\n",
    "    # store the scales\n",
    "    scale = torch.zeros(output_dim)\n",
    "\n",
    "    for index in range(output_dim):\n",
    "        sub_tensor = r_tensor.select(dim, index)\n",
    "        scale[index] = get_q_scale_symmetric(sub_tensor, dtype=dtype)\n",
    "\n",
    "    # reshape the scale\n",
    "    scale_shape = [1] * r_tensor.dim()\n",
    "    scale_shape[dim] = -1\n",
    "    scale = scale.view(scale_shape)\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "        r_tensor, scale=scale, zero_point=0, dtype=dtype)\n",
    "   \n",
    "    return quantized_tensor, scale"
   ],
   "id": "3f561b088b70725b",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:44:29.179783Z",
     "start_time": "2024-11-05T11:44:29.174713Z"
    }
   },
   "cell_type": "code",
   "source": "test_tensor",
   "id": "ebcd45ac663547d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 191.6000,  -13.5000,  728.6000],\n",
       "        [  92.1400,  295.5000, -184.0000],\n",
       "        [   0.0000,  684.6000,  245.5000]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:40:47.077151Z",
     "start_time": "2024-11-05T11:40:47.073669Z"
    }
   },
   "cell_type": "code",
   "source": "q_tensor,scale = linear_q_symmetric_per_channel(test_tensor,dim =0)",
   "id": "486dd5aa31a2a1e1",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:40:54.233085Z",
     "start_time": "2024-11-05T11:40:54.227794Z"
    }
   },
   "cell_type": "code",
   "source": "q_tensor",
   "id": "dd92e18320627271",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 33,  -2, 127],\n",
       "        [ 40, 127, -79],\n",
       "        [  0, 127,  46]], dtype=torch.int8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:02:12.298555Z",
     "start_time": "2024-11-05T13:02:12.293861Z"
    }
   },
   "cell_type": "code",
   "source": "scale",
   "id": "a8ae737c12f71c3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7370, 2.3268, 5.3906])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:05:10.563791Z",
     "start_time": "2024-11-05T13:05:10.560684Z"
    }
   },
   "cell_type": "code",
   "source": "d_quantized_tensor = get_dequantised_tensor(q_tensor,scale,0)",
   "id": "7068f9acf3a53042",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:05:13.447045Z",
     "start_time": "2024-11-05T13:05:13.442021Z"
    }
   },
   "cell_type": "code",
   "source": "d_quantized_tensor",
   "id": "87c5082bba241bf6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 189.3213,  -11.4740,  728.6000],\n",
       "        [  93.0709,  295.5000, -183.8150],\n",
       "        [   0.0000,  684.6000,  247.9653]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:05:59.154544Z",
     "start_time": "2024-11-05T13:05:59.149312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quantization error\n",
    "torch.square(test_tensor-d_quantized_tensor).mean()"
   ],
   "id": "a7479a3a5644e9f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8084)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Per group",
   "id": "44af85880dd9a164"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Note:**<br>\n",
    "    - Per-group quantization can require a lot more memory. \n",
    "Let's say we want to quantize a tensor in 4-bit, and we choose group_size = 32, symmetric mode (z=0), and we store the scales in FP16. \n",
    "It means that we're actually quantizing the tensor in 4.5 bits since we have: 4 bit (each element is stored in 4 bit) 16/32 bit (scale in 16 bits for every 32 elements)"
   ],
   "id": "9431c7ab8f92eb53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f21b99e4b662a26e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:18:07.065384Z",
     "start_time": "2024-11-05T13:18:07.061390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_q_symmetric_per_group(tensor, group_size,\n",
    "                                 dtype=torch.int8):\n",
    "    \n",
    "    t_shape = tensor.shape\n",
    "    assert t_shape[1] % group_size == 0\n",
    "    assert tensor.dim() == 2\n",
    "    \n",
    "    tensor = tensor.view(-1, group_size)\n",
    "    \n",
    "    quantized_tensor, scale = linear_q_symmetric_per_channel(\n",
    "                                tensor, dim=0, dtype=dtype)\n",
    "    \n",
    "    quantized_tensor = quantized_tensor.view(t_shape)\n",
    "    \n",
    "    return quantized_tensor, scale"
   ],
   "id": "e96e3a1252b06cc9",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:25:48.901243Z",
     "start_time": "2024-11-05T13:25:48.898077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_dequantization_per_group(quantized_tensor, scale, \n",
    "                                    group_size):\n",
    "    \n",
    "    q_shape = quantized_tensor.shape\n",
    "    quantized_tensor = quantized_tensor.view(-1, group_size)\n",
    "    \n",
    "    dequantized_tensor =  scale * quantized_tensor.float()\n",
    "    \n",
    "    dequantized_tensor = dequantized_tensor.view(q_shape)\n",
    "    \n",
    "    return dequantized_tensor"
   ],
   "id": "b78afd0e57cbaf82",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:22:08.754333Z",
     "start_time": "2024-11-05T13:22:08.750753Z"
    }
   },
   "cell_type": "code",
   "source": "test_tensor = torch.rand((6, 6))",
   "id": "bf014792b6de2520",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:22:13.760956Z",
     "start_time": "2024-11-05T13:22:13.755704Z"
    }
   },
   "cell_type": "code",
   "source": "test_tensor",
   "id": "709586500cc9469a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4197, 0.6648, 0.5409, 0.3064, 0.1431, 0.0918],\n",
       "        [0.7418, 0.2223, 0.6072, 0.0738, 0.8673, 0.9437],\n",
       "        [0.8802, 0.7510, 0.4111, 0.5284, 0.0147, 0.2914],\n",
       "        [0.0059, 0.5684, 0.9731, 0.6982, 0.8171, 0.9633],\n",
       "        [0.3606, 0.0750, 0.1799, 0.5641, 0.1451, 0.7478],\n",
       "        [0.2887, 0.5852, 0.2396, 0.2173, 0.3833, 0.9906]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:22:42.909205Z",
     "start_time": "2024-11-05T13:22:42.906322Z"
    }
   },
   "cell_type": "code",
   "source": "group_size = 3",
   "id": "20c87cb5f2219a6f",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:26:35.542847Z",
     "start_time": "2024-11-05T13:26:35.539288Z"
    }
   },
   "cell_type": "code",
   "source": "quantized_tensor,scale = linear_q_symmetric_per_group(test_tensor,group_size)",
   "id": "6fbf6e1b9e6e6ee3",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:26:36.828494Z",
     "start_time": "2024-11-05T13:26:36.825492Z"
    }
   },
   "cell_type": "code",
   "source": "dequantized_tensor = linear_dequantization_per_group(quantized_tensor,scale,group_size)",
   "id": "ddf72ad556efa886",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:26:43.930208Z",
     "start_time": "2024-11-05T13:26:43.924859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quantization error\n",
    "torch.square(test_tensor-dequantized_tensor).mean()"
   ],
   "id": "b37c815f11c30c12",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3180e-06)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quantization in Neural Network",
   "id": "97ae87702aba7462"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### In a neural network, we can quantize the **weights** but also the **activation**. Depending on what we quantize, the **storage** and the **computation** are not the same!",
   "id": "f560a4f72897ca11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "|  |  | |\n",
    "|--|--|--|\n",
    "|Storage| Quantized Weight + Activation (e.g. W8A32) |Quantized Weight + Quantized Activation (e.g. W8A8)|\n",
    " |Computation| Floating point arithmetics (FP32,FP16,BF16...) |Integer based arithmetics (INT8, INT4...|\n",
    " |Note|we need to dequantize the weights to perform the floating point computation!|Not supported by all hardware!|"
   ],
   "id": "2b865e1cb085e3b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Quantization: Inference",
   "id": "5c6702475c1531f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `W8A32` means weights in 8-bits and activations in 32-bits.\n",
    "- For simplicity, the linear layer will be without bias."
   ],
   "id": "d3481241b67aecd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:43:50.719414Z",
     "start_time": "2024-11-05T13:43:50.716302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def quantized_linear_W8A32_without_bias(input, q_w, s_w, z_w):\n",
    "    assert input.dtype == torch.float32\n",
    "    assert q_w.dtype == torch.int8\n",
    "\n",
    "    dequantized_weight = q_w.to(torch.float32) * s_w + z_w\n",
    "    output = torch.nn.functional.linear(input, dequantized_weight)\n",
    "    \n",
    "    return output"
   ],
   "id": "209673a5f9cde948",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:44:14.606555Z",
     "start_time": "2024-11-05T13:44:14.603173Z"
    }
   },
   "cell_type": "code",
   "source": "input = torch.tensor([1, 2, 3], dtype=torch.float32)",
   "id": "c0de2bdd3ddedd0b",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:44:24.471445Z",
     "start_time": "2024-11-05T13:44:24.468490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight = torch.tensor([[-2,   -1.13, 0.42],\n",
    "                       [-1.51, 0.25, 1.62],\n",
    "                       [0.23,  1.35, 2.15]])"
   ],
   "id": "aadb1f2ab7142e22",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:45:17.556922Z",
     "start_time": "2024-11-05T13:45:17.552723Z"
    }
   },
   "cell_type": "code",
   "source": "weight.dtype",
   "id": "292bc71e85e58742",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af1fd62bcafd4dab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:46:15.655971Z",
     "start_time": "2024-11-05T13:46:15.652523Z"
    }
   },
   "cell_type": "code",
   "source": "q_w, s_w  = linear_q_symmetric_per_channel(weight,dim=0)",
   "id": "4559a1205648507a",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:46:24.136612Z",
     "start_time": "2024-11-05T13:46:24.132976Z"
    }
   },
   "cell_type": "code",
   "source": "q_w.dtype",
   "id": "fdcbdd825e6474f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int8"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:46:35.935142Z",
     "start_time": "2024-11-05T13:46:35.930434Z"
    }
   },
   "cell_type": "code",
   "source": "s_w",
   "id": "c1c56e7f9228d1f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0157],\n",
       "        [0.0128],\n",
       "        [0.0169]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:47:42.066539Z",
     "start_time": "2024-11-05T13:47:42.016785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = quantized_linear_W8A32_without_bias(input,\n",
    "                                             q_w,\n",
    "                                             s_w,\n",
    "                                             0)"
   ],
   "id": "60228d11334ff54c",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:48:40.069134Z",
     "start_time": "2024-11-05T13:48:40.064948Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"This is the W8A32 output: {output}\")",
   "id": "88164d0299afefda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the W8A32 output: tensor([-2.9921,  3.8650,  9.3957])\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:48:51.505453Z",
     "start_time": "2024-11-05T13:48:51.502308Z"
    }
   },
   "cell_type": "code",
   "source": "fp32_output = torch.nn.functional.linear(input, weight)",
   "id": "6e7863c656c610db",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:49:02.553916Z",
     "start_time": "2024-11-05T13:49:02.549332Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"This is the output if we don't quantize: {fp32_output}\")",
   "id": "76995f33063e82f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the output if we don't quantize: tensor([-3.0000,  3.8500,  9.3800])\n"
     ]
    }
   ],
   "execution_count": 119
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
